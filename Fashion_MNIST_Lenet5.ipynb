{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST-Lenet5.ipynb",
      "provenance": [],
      "mount_file_id": "1fe6MXABVrSTaXLqDccyfTxyc0iv7bNzo",
      "authorship_tag": "ABX9TyMieadVHhcZJBbZyzzrdvWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinnyjinny/Fashion-MNIST-Pytorch/blob/main/Fashion_MNIST_Lenet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwilih4W4nH5"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1c5QsPr5BKo"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777) \n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k6MADMU9Os8"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "learning_rate = 0.001 \n",
        "training_epochs = 50 \n",
        "batch_size = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_7CpQjjLUhN"
      },
      "source": [
        "# input tensor resizing\n",
        "\n",
        "transforms=transforms.Compose([\n",
        "                               transforms.Resize((35,35)),\n",
        "                               transforms.ToTensor(),\n",
        "                               ])\n",
        "\n",
        "mnist_train = dsets.FashionMNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms,\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.FashionMNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms,\n",
        "                         download=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V9vrZnrU_sO"
      },
      "source": [
        "train_loader = DataLoader(dataset=mnist_train,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          drop_last=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=mnist_test,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z582aqjnY9qJ"
      },
      "source": [
        "class Lenet5(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Lenet5,self).__init__()\n",
        "\n",
        "    self.l1=torch.nn.Conv2d(1,6,kernel_size=5,padding=0,stride=1)\n",
        "    self.x1=torch.nn.Tanh()\n",
        "    self.l2=torch.nn.AvgPool2d(kernel_size=2,padding=0,stride=2)\n",
        "\n",
        "    self.l3=torch.nn.Conv2d(6,16,kernel_size=5,padding=0,stride=1)\n",
        "    self.x2=torch.nn.Tanh()\n",
        "    self.l4=torch.nn.AvgPool2d(kernel_size=2,padding=0,stride=2)\n",
        "\n",
        "    self.l5=torch.nn.Flatten()\n",
        "\n",
        "    self.l6=torch.nn.Linear(16*5*5,120,bias=True)\n",
        "    self.x3=torch.nn.Tanh()\n",
        "\n",
        "    self.l7=torch.nn.Linear(120,84,bias=True)\n",
        "    self.x4=torch.nn.Tanh()\n",
        "\n",
        "    self.l8=torch.nn.Linear(84,10,bias=True)\n",
        "  \n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.l1(x)\n",
        "    out=self.x1(out)\n",
        "    out=self.l2(out)\n",
        "    out=self.l3(out)\n",
        "    out=self.x2(out)\n",
        "    out=self.l4(out)\n",
        "\n",
        "    out=out.view(out.size(0),-1)\n",
        "\n",
        "    out=self.l6(out)\n",
        "    out=self.x3(out)\n",
        "    out=self.l7(out)\n",
        "    out=self.x4(out)\n",
        "    out=self.l8(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU0Mow59ZJHM"
      },
      "source": [
        "model = Lenet5().to(device) # device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeK8r6UzZREc"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYS9aSBohxM-"
      },
      "source": [
        "# train my model\n",
        "total_batch = len(train_loader)\n",
        "print('Learning stared. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "\n",
        "  for X, Y in train_loader:\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "\n",
        "      optimizer.zero_grad() # forward pass: 파이토치에서는 미분을 통해 얻은 기울기(gradient)를 0으로 초기화하고 학습을 진행\n",
        "      hypothesis = model(X) \n",
        "      cost = loss(hypothesis, Y) \n",
        "\n",
        "      cost.backward() # backward pass: 가중치 업데이트 \n",
        "      optimizer.step() \n",
        "\n",
        "      avg_cost += cost / total_batch # 각 배치마다 계산된 손실값의 평균\n",
        "  \n",
        "  print('[Epoch: {:>2}] cost = {:>.9}'.format(epoch + 1, avg_cost)) # 1 에폭마다 손실값이 얼마나 나오는지 확인\n",
        "print('Learning Finished!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1QpPcMWpuO5"
      },
      "source": [
        "# validation loss 계산하기\n",
        "accuracy = 0\n",
        "total_batch = len(test_loader)\n",
        "\n",
        "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
        "with torch.no_grad(): \n",
        "  model.eval() \n",
        "\n",
        "  for X_test, Y_test in test_loader:\n",
        "      X_test = X_test.to(device)\n",
        "      Y_test = Y_test.to(device)\n",
        "\n",
        "      prediction = model(X_test)\n",
        "      correction_prediction = torch.argmax(prediction, 1) == Y_test \n",
        "      accuracy += correct_prediction.float().mean() # 모든 배치의 정확도를 누적\n",
        "      # accuracy = correct_prediction.float().mean()을 하면 하나의 배치에 해당된 정확도를 알 수 있다\n",
        "\n",
        "print('Accuracy:' accuracy.item()/total_batch) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}